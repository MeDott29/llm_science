{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "hypothesis: Grouping similar questions together will enhance the performance of the model in answering multiple-choice questions.\n",
    "Rationale: The idea behind this hypothesis is that similar questions often share common themes, concepts, or structures. By grouping these questions together, the model can leverage the shared information to better understand the context and make more accurate predictions. This approach could potentially allow the model to recognize patterns or relationships between questions that it might miss when the questions are presented individually.\n",
    "Proposed Method: To test this hypothesis, we could modify the training process to present batches of similar questions together. We could use various strategies to determine similarity, such as analyzing the content of the questions, the subject matter, or the structure of the questions. We could then compare the performance of the model when trained with these batches of similar questions versus its performance when trained with randomly ordered questions.\n",
    "Expected Outcome: If the hypothesis is correct, we would expect to see an improvement in the model's performance when it is trained with batches of similar questions. This could manifest as an increase in accuracy, a decrease in errors, or other measurable improvements in the model's ability to answer multiple-choice questions.\n",
    "Potential Challenges: One challenge in testing this hypothesis could be determining the best way to group similar questions together. Different strategies might yield different results, and it could require some experimentation to find the most effective approach. Additionally, it might be necessary to adjust the model's architecture or training process to effectively leverage the grouped questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import re\n",
    "from openai import OpenAI\n",
    "import instructor\n",
    "from instructor import patch\n",
    "from pydantic import BaseModel\n",
    "from typing import Dict\n",
    "\n",
    "client = patch(OpenAI())\n",
    "df = pd.read_csv('train.csv')\n",
    "row = df.iloc[0]\n",
    "\n",
    "test_item = row['prompt']  + ' ' + row['A'] + ' ' + row['B'] + ' ' + row['C'] + ' ' + row['D'] + ' ' + row['E'] + ' ' + row['answer']\n",
    "\n",
    "client = instructor.patch(client)\n",
    "\n",
    "class QuestionGroup(BaseModel):\n",
    "    first: str\n",
    "    second: str\n",
    "    third: str\n",
    "    \n",
    "resp = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo-1106\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\", \n",
    "            \"content\": f\"Read the MCQ and give the top three terms you would use to search for an answer: {test_item}\",\n",
    "        },\n",
    "    ],\n",
    "    response_model=QuestionGroup\n",
    ")\n",
    "resp\n",
    "print(resp)\n",
    "\n",
    "def clean_string(s):\n",
    "  # Remove everything inside parentheses\n",
    "  s = re.sub(r'\\([^()]*\\)', '', s)\n",
    "  \n",
    "  # Remove all non-alphabetical characters except spaces\n",
    "  s = re.sub(r'[^a-zA-Z ]', '', s)\n",
    "  \n",
    "  # Remove spaces from the end of the string\n",
    "  s = s.rstrip()\n",
    "  \n",
    "  return s\n",
    "\n",
    "search_term = clean_string(resp.first)\n",
    "print(search_term)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
